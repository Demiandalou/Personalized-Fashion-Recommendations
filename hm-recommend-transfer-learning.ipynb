{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-04-15T14:38:23.753271Z","iopub.status.busy":"2022-04-15T14:38:23.752928Z","iopub.status.idle":"2022-04-15T14:38:23.784598Z","shell.execute_reply":"2022-04-15T14:38:23.783152Z","shell.execute_reply.started":"2022-04-15T14:38:23.753178Z"},"trusted":true,"id":"SMahxuEmxZuH"},"outputs":[],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import os\n","data_dir = '../input/h-and-m-personalized-fashion-recommendations'\n","img_dir = '../input/h-and-m-personalized-fashion-recommendations/images'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-15T14:38:23.787205Z","iopub.status.busy":"2022-04-15T14:38:23.786770Z","iopub.status.idle":"2022-04-15T14:38:23.791721Z","shell.execute_reply":"2022-04-15T14:38:23.790353Z","shell.execute_reply.started":"2022-04-15T14:38:23.787158Z"},"trusted":true,"id":"OoH8H_30xZuL"},"outputs":[],"source":["# !wget https://github.com/explosion/spacy-models/releases/download/en_vectors_web_lg-2.1.0/en_vectors_web_lg-2.1.0.tar.gz -O en_vectors_web_lg-2.1.0.tar.gz\n","# !pip install en_vectors_web_lg-2.1.0.tar.gz\n","# import en_vectors_web_lg"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-15T14:38:23.794411Z","iopub.status.busy":"2022-04-15T14:38:23.793587Z","iopub.status.idle":"2022-04-15T14:38:25.917883Z","shell.execute_reply":"2022-04-15T14:38:25.916707Z","shell.execute_reply.started":"2022-04-15T14:38:23.794361Z"},"trusted":true,"id":"mMBpzk3BxZuM"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from collections import Counter\n","import os\n","import torch\n","import re\n","import time\n","import copy\n","import math\n","import pickle\n","\n","import seaborn as sns\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-15T14:38:25.920736Z","iopub.status.busy":"2022-04-15T14:38:25.920414Z","iopub.status.idle":"2022-04-15T14:38:25.932342Z","shell.execute_reply":"2022-04-15T14:38:25.931221Z","shell.execute_reply.started":"2022-04-15T14:38:25.920695Z"},"trusted":true,"id":"UZPyZ1-0xZuM"},"outputs":[],"source":["def apk(actual, predicted, k=10):\n","    if len(predicted)>k: predicted = predicted[:k]\n","    score = 0.0\n","    num_hits = 0.0\n","    for i,p in enumerate(predicted):\n","        if p in actual and p not in predicted[:i]:\n","            num_hits += 1.0\n","            score += num_hits / (i+1.0)\n","    if not actual:\n","        return 0.0\n","    return score / min(len(actual), k)\n","\n","def mapk(actual, predicted, k=12):\n","    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted) if a]) # CHANGES: ignore null actual (variable=a)\n","def calculate_mapk(df):\n","    res = mapk(\n","        df['valid_true'].map(lambda x: x.split()), \n","        df['prediction'].map(lambda x: x.split()), \n","        k=12\n","    )\n","    return res"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-15T14:38:25.933950Z","iopub.status.busy":"2022-04-15T14:38:25.933523Z","iopub.status.idle":"2022-04-15T14:38:25.951197Z","shell.execute_reply":"2022-04-15T14:38:25.950289Z","shell.execute_reply.started":"2022-04-15T14:38:25.933918Z"},"trusted":true,"id":"D6MCVdP_xZuN"},"outputs":[],"source":["save_dir = '../input/embeddings'\n","def clean_text(w):\n","    return re.sub(\n","            r\"([.,'!?\\\"()*#:;])\",\n","            '',\n","            w.lower()\n","            ).replace('-', ' ').replace('/', ' ')\n","\n","def get_glove_embedding(reviews, data_dir):\n","    token_file = os.path.join(data_dir,'token_to_ix.pkl')\n","    glove_file = os.path.join(data_dir,'train_glove.npy')\n","    if os.path.exists(glove_file) and os.path.exists(token_file):\n","        print(\"Loading saved embedding\")\n","        return pickle.load(open(token_file, \"rb\")), np.load(glove_file)\n","    all_reviews = {}\n","    for idx, s in enumerate(reviews):\n","        all_reviews[idx] = clean_text(s).split()\n","\n","    from collections import defaultdict\n","    token_to_ix = defaultdict(int)\n","    token_to_ix['UNK'] = 1\n","\n","    spacy_tool = en_vectors_web_lg.load()\n","    pretrained_emb = []\n","    pretrained_emb.append(spacy_tool('UNK').vector)\n","  \n","    for k, v in all_reviews.items():\n","        for word in v:\n","            if word not in token_to_ix:\n","                token_to_ix[word] = len(token_to_ix)\n","                pretrained_emb.append(spacy_tool(word).vector)\n","\n","    pretrained_emb = np.array(pretrained_emb)\n","    np.save(glove_file, pretrained_emb)\n","    pickle.dump(token_to_ix, open(token_file, \"wb\"))\n","    return token_to_ix, pretrained_emb\n","\n","def embed_text(x, max_len, token2ix):\n","    ques_ix = np.zeros(max_len, np.int64)\n","    x = clean_text(x).split()\n","    for ix, word in enumerate(x):\n","        if word in token2ix:\n","            ques_ix[ix] = token2ix[word]\n","        else:\n","            ques_ix[ix] = 1\n","        if ix + 1 == max_len:\n","            break\n","    return ques_ix\n","\n","def tokenize(reviews):\n","    token2ix = {'PAD': 0, 'UNK': 1, 'SS' : 2}\n","    for r in reviews:\n","        r = clean_text(r).split()\n","        for word in r:\n","            if word not in token2ix:\n","                token2ix[word] = len(token2ix)\n","    return token2ix"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-15T14:38:25.954843Z","iopub.status.busy":"2022-04-15T14:38:25.953878Z","iopub.status.idle":"2022-04-15T14:38:25.967824Z","shell.execute_reply":"2022-04-15T14:38:25.966995Z","shell.execute_reply.started":"2022-04-15T14:38:25.954803Z"},"trusted":true,"id":"hSVrs175xZuO"},"outputs":[],"source":["class Ranking(nn.Module):\n","    def __init__(self, watch_time_feature_size, hidden_size, candidate_size):\n","        super(Ranking, self).__init__()\n","        self.fc1 = nn.Linear(watch_time_feature_size, hidden_size)\n","        self.fc2 = nn.Linear(hidden_size, hidden_size)\n","        self.fc3 = nn.Linear(hidden_size, 1)\n","\n","    def forward(self, src):\n","        \"\"\"\n","        input is (batch_size, n_item, watch_time_feature_size), and output is (batch_size, n_item).\n","        \"\"\"\n","        h = F.relu(self.fc1(src))\n","        h = F.relu(self.fc2(h))\n","        out = F.relu(self.fc3(h))\n","        return out.squeeze(-1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-15T14:38:25.971393Z","iopub.status.busy":"2022-04-15T14:38:25.969005Z","iopub.status.idle":"2022-04-15T14:38:25.986135Z","shell.execute_reply":"2022-04-15T14:38:25.985276Z","shell.execute_reply.started":"2022-04-15T14:38:25.971347Z"},"trusted":true,"id":"-Hy8MoQzxZuO"},"outputs":[],"source":["def train_ranking(model, get_batch_iter, batch_size):\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, betas=(0.9, 0.98), eps=1e-9)\n","    epochs = 5\n","    for epoch in range(epochs):\n","        total_loss = 0\n","        batch_iter = get_batch_iter()\n","        for iter_, (mini_x, mini_label) in enumerate(batch_iter):\n","#         for iter_, (mini_x1, mini_y, min_input_ids, min_token_type_ids, min_attention_mask)\\\n","#           in enumerate(batch_iter):\n","            out = model(mini_x)  # (batch_size, n_item)\n","            optimizer.zero_grad()\n","            loss = nn.MSELoss(reduction='sum')(out, mini_label)  # todo: use sigmoid cross entropy loss\n","            total_loss += loss.item()\n","            if iter_ != 0 and (iter_ + 1) % 1000 == 0:\n","                print(f'epoch: {epoch + 1}, iter: {iter_ + 1}, loss: {total_loss/10}')\n","                total_loss = 0\n","            loss.backward()\n","            optimizer.step()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-15T14:38:25.988126Z","iopub.status.busy":"2022-04-15T14:38:25.987550Z","iopub.status.idle":"2022-04-15T14:38:26.000011Z","shell.execute_reply":"2022-04-15T14:38:25.998919Z","shell.execute_reply.started":"2022-04-15T14:38:25.988084Z"},"trusted":true,"id":"a3woVaXBxZuP"},"outputs":[],"source":["# tmp = pd.read_csv(os.path.join(data_dir,'transactions_train.csv'), nrows=10000)\\\n","#             .sort_values(by = ['customer_id','article_id'], ascending=True)\n","# \n","# Counter(tmp['article_id']).most_common()[:5]\n","# set(tmp[tmp['article_id']==685687004]['price']) # same article_id in trasaction can have diff prices\n","# set(tmp[tmp['article_id']==685687004]['customer_id'])"]},{"cell_type":"markdown","metadata":{"id":"nz02nbzbxZuQ"},"source":["### Load Data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-15T14:38:26.001766Z","iopub.status.busy":"2022-04-15T14:38:26.001400Z","iopub.status.idle":"2022-04-15T14:38:27.861549Z","shell.execute_reply":"2022-04-15T14:38:27.860285Z","shell.execute_reply.started":"2022-04-15T14:38:26.001735Z"},"trusted":true,"id":"irRf7CPYxZuS"},"outputs":[],"source":["import datetime\n","articles = pd.read_csv(os.path.join(data_dir,'articles.csv'))\\\n","            .sort_values(by = ['article_id'], ascending=True)\n","# customers = pd.read_csv(os.path.join(data_dir,'customers.csv')) # , nrows=100000\n","# transactions = pd.read_csv(os.path.join(data_dir,'transactions_train.csv')) # , nrows=200000\n","\n","customers = pd.read_csv('../input/sample-data/customers_sample.csv')\n","transactions = pd.read_csv('../input/sample-data/transaction_sample.csv')\n","transactions['t_dat'] = transactions['t_dat'].map(lambda x: datetime.datetime.strptime(x, '%Y-%m-%d'))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-15T14:38:27.864699Z","iopub.status.busy":"2022-04-15T14:38:27.864433Z","iopub.status.idle":"2022-04-15T14:38:27.871118Z","shell.execute_reply":"2022-04-15T14:38:27.869835Z","shell.execute_reply.started":"2022-04-15T14:38:27.864666Z"},"trusted":true,"id":"mGOpFblcxZuT"},"outputs":[],"source":["# print(max(transactions['t_dat'])) # 2020-09-22 00:00:00\n","# transactions = \n","# print(len(transactions[transactions['t_dat'] > pd.to_datetime('2020-08-22')])) #1155933\n","get_sample = 0\n","if get_sample:\n","    transactions = transactions[transactions['t_dat'] > pd.to_datetime('2020-08-22')]\n","    cnter = Counter(transactions['customer_id']).most_common()[:2000]\n","    keep_cids = [i[0] for i in cnter]\n","    print(keep_cids[:5], cnter[-1])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-15T14:38:27.873024Z","iopub.status.busy":"2022-04-15T14:38:27.872666Z","iopub.status.idle":"2022-04-15T14:38:27.948036Z","shell.execute_reply":"2022-04-15T14:38:27.947236Z","shell.execute_reply.started":"2022-04-15T14:38:27.872957Z"},"trusted":true,"id":"t4li8wkfxZuU"},"outputs":[],"source":["keep_cids = customers['customer_id'].unique()\n","# keep_cids = set(transactions['customer_id'].unique())\n","customers = customers[customers['customer_id'].isin(keep_cids)]\n","customers = customers.sort_values(by = ['customer_id'], ascending=True)\n","\n","# keep_cids = keep_cids.intersection(set(customers['customer_id'].unique()))\n","transactions = transactions[transactions['customer_id'].isin(keep_cids)]\n","transactions = transactions.sort_values(by = ['customer_id','article_id'], ascending=True)\n","print(len(keep_cids))\n","\n","keep_aid = list(transactions['article_id'].unique())\n","articles = articles[articles['article_id'].isin(keep_aid)].reset_index(drop=True)\n","len(keep_aid), len(articles)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-15T14:38:27.949791Z","iopub.status.busy":"2022-04-15T14:38:27.949410Z","iopub.status.idle":"2022-04-15T14:38:27.954653Z","shell.execute_reply":"2022-04-15T14:38:27.953780Z","shell.execute_reply.started":"2022-04-15T14:38:27.949746Z"},"trusted":true,"id":"1GRMBrpdxZuU"},"outputs":[],"source":["# customers.to_csv('customers_large_sample.csv', index = False)\n","# transactions.to_csv('transactions_large_sample.csv', index = False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-15T14:38:27.956170Z","iopub.status.busy":"2022-04-15T14:38:27.955886Z","iopub.status.idle":"2022-04-15T14:38:27.967995Z","shell.execute_reply":"2022-04-15T14:38:27.967290Z","shell.execute_reply.started":"2022-04-15T14:38:27.956142Z"},"trusted":true,"id":"RBEfatbSxZuU"},"outputs":[],"source":["len(customers), len(transactions), len(articles)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-15T14:38:27.969729Z","iopub.status.busy":"2022-04-15T14:38:27.969324Z","iopub.status.idle":"2022-04-15T14:38:28.013882Z","shell.execute_reply":"2022-04-15T14:38:28.013225Z","shell.execute_reply.started":"2022-04-15T14:38:27.969695Z"},"trusted":true,"id":"H-zphMOWxZuV"},"outputs":[],"source":["customers[['FN','Active','club_member_status','fashion_news_frequency']] = customers[['FN','Active', 'club_member_status','fashion_news_frequency']].fillna(0)\n","print('FN',customers['FN'].unique(), '\\nclub_member_status',customers['club_member_status'].unique(),\\\n","        '\\nage',customers['age'].unique(),'\\nActive',customers['Active'].unique(),\\\n","      '\\nfashion_news_frequency', customers['fashion_news_frequency'].unique())\n","\n","customers['club_member_status'] = customers['club_member_status'].replace('ACTIVE', 1);customers['club_member_status'] = customers['club_member_status'].replace('PRE-CREATE', 2);customers['club_member_status'] = customers['club_member_status'].replace('LEFT CLUB', 3)\n","\n","customers['fashion_news_frequency'] = customers['fashion_news_frequency'].replace('NONE', 0);customers['fashion_news_frequency'] = customers['fashion_news_frequency'].replace('None', 0)\n","customers['fashion_news_frequency'] = customers['fashion_news_frequency'].replace('Regularly', 1);customers['fashion_news_frequency'] = customers['fashion_news_frequency'].replace('Monthly', 2)\n","\n","customers[['age','FN','Active','club_member_status','fashion_news_frequency']] = \\\n","        customers[['age','FN','Active','club_member_status','fashion_news_frequency']].astype('float64')\n","customers.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-15T14:38:28.015512Z","iopub.status.busy":"2022-04-15T14:38:28.015117Z","iopub.status.idle":"2022-04-15T14:38:28.018699Z","shell.execute_reply":"2022-04-15T14:38:28.018050Z","shell.execute_reply.started":"2022-04-15T14:38:28.015478Z"},"trusted":true,"id":"HvwYrit3xZuV"},"outputs":[],"source":["# map_cid_to_aid = {cid:list(transactions[transactions['customer_id']==cid]['article_id']) for cid in keep_cids}\n","# transactions.groupby('customer_id')['article_id'].apply(list).reset_index()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-15T14:38:28.020397Z","iopub.status.busy":"2022-04-15T14:38:28.020013Z","iopub.status.idle":"2022-04-15T14:38:28.043879Z","shell.execute_reply":"2022-04-15T14:38:28.043272Z","shell.execute_reply.started":"2022-04-15T14:38:28.020356Z"},"trusted":true,"id":"yB6HxpuzxZuV"},"outputs":[],"source":["# customers.head()\n","print(len(customers['customer_id'].unique()), len(customers)) #1371980\n","print(len(transactions))\n","transactions.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-15T14:38:28.045463Z","iopub.status.busy":"2022-04-15T14:38:28.045099Z","iopub.status.idle":"2022-04-15T14:38:29.339802Z","shell.execute_reply":"2022-04-15T14:38:29.339038Z","shell.execute_reply.started":"2022-04-15T14:38:28.045420Z"},"trusted":true,"id":"25qoXP5qxZuV"},"outputs":[],"source":["all_article_desp = []\n","use_cols = ['prod_name', 'product_type_name', 'product_group_name', 'graphical_appearance_name',\n","           'colour_group_name', 'perceived_colour_value_name', 'perceived_colour_master_name',\n","           'department_name', 'index_name', 'index_group_name', 'section_name',\n","           'garment_group_name', 'detail_desc']\n","\n","# articles = articles.dropna(subset=use_cols, how='any').reset_index()\n","max_len = 0\n","for c in use_cols:\n","    arr = [len(str(i).split()) for i in articles[c]]\n","    length = int(np.percentile(arr,90))\n","    max_len+=length\n","    articles[c] = articles[c].apply(lambda x: ' '.join(str(x).split()[:length]))\n","\n","for i in range(len(articles)):\n","    text = ''\n","    for c in use_cols:\n","        text += articles[c][i] + ' [SEP] '\n","    all_article_desp.append(text)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-15T14:38:29.341322Z","iopub.status.busy":"2022-04-15T14:38:29.341060Z","iopub.status.idle":"2022-04-15T14:38:30.294048Z","shell.execute_reply":"2022-04-15T14:38:30.293137Z","shell.execute_reply.started":"2022-04-15T14:38:29.341290Z"},"trusted":true,"id":"Db9CiMqHxZuW"},"outputs":[],"source":["token2ix, pretrained_emb = get_glove_embedding(all_article_desp,save_dir)\n","article_emb = np.array([embed_text(x,max_len,token2ix) for x in all_article_desp])\n","aid2emb = {articles['article_id'][i]: article_emb[i] for i in range(len(articles))}\n","aid2text = {articles['article_id'][i]: all_article_desp[i] for i in range(len(articles))}\n","print(len(articles), len(articles['article_id'].unique()), len(aid2text))#, aid2emb[108775015].shape)\n","article_emb.shape, pretrained_emb.shape, len(token2ix) # vocab size"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-15T14:38:30.295636Z","iopub.status.busy":"2022-04-15T14:38:30.295332Z","iopub.status.idle":"2022-04-15T14:38:30.306657Z","shell.execute_reply":"2022-04-15T14:38:30.305724Z","shell.execute_reply.started":"2022-04-15T14:38:30.295597Z"},"trusted":true,"id":"iYb3pyouxZuW"},"outputs":[],"source":["\n","# previous model\n","class CandidateGeneration_basic(nn.Module):\n","    def __init__(self, embed_item_size, hidden_size):\n","        super(CandidateGeneration_basic, self).__init__()\n","        self.embedding = nn.Embedding(num_embeddings=len(token2ix),\n","                                      embedding_dim=300)\n","        self.personal_fc = nn.Linear(1, embed_item_size)\n","        self.fc1 = nn.Linear(embed_item_size, hidden_size)  # noqa: E226\n","        self.fc2 = nn.Linear(hidden_size, embed_item_size)\n","        self.fc3 = nn.Linear(embed_item_size, embed_item_size)\n","        self.dropout = nn.Dropout(0.5)\n","\n","#     def forward(self, context_src, personal_src, item_src):\n","    def forward(self, min_input_ids, min_token_type_ids, min_attention_mask, personal_src, item_src):\n","        \n","        personal_h = self.personal_fc(personal_src)  # (batch_size, n_personal, embed_item_size)\n","        h = torch.cat((context_src, personal_h), 1)  # (batch_size, 1+n_personal, embed_item_size)\n","        \n","        h = F.relu(self.fc1(h))\n","        h = self.dropout(h)\n","        h = F.relu(self.fc2(h))\n","        h = self.dropout(h)\n","        personal_context = F.relu(self.fc3(h))  # (batch_size, 1+n_personal, embed_item_size)\n","        # personal_context is (batch_size, embed_item_size)'s shape average, take inner prod with item_src\n","#         print(personal_context)\n","        out = torch.matmul(personal_context.mean(axis=1), item_src.t())  # (batch_size, n_item) = (batch_size, embed_item_size) * (embed_item_size, n_item)  # noqa: E501\n","        sigmoid = nn.Sigmoid()\n","        out = sigmoid(out) # (batch_size, n_item)\n","        return out"]},{"cell_type":"markdown","metadata":{"id":"KCOY5widxZuW"},"source":["## main -- candidate generation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-15T14:38:30.309163Z","iopub.status.busy":"2022-04-15T14:38:30.308242Z","iopub.status.idle":"2022-04-15T14:38:30.338314Z","shell.execute_reply":"2022-04-15T14:38:30.337433Z","shell.execute_reply.started":"2022-04-15T14:38:30.309099Z"},"trusted":true,"id":"i4ohXTYcxZuW"},"outputs":[],"source":["# transactions.groupby(['customer_id', 'article_id']).count().reset_index()\n","aid_to_article = {}\n","for idx, article in enumerate(transactions['article_id'].unique()):\n","    aid_to_article[idx] = article\n","article_to_aid = {aid_to_article[k]:k for k in aid_to_article}\n","# cid_to_article\n","cid_to_customer = {}\n","for idx, customer in enumerate(transactions['customer_id'].unique()):\n","    cid_to_customer[idx] = customer\n","customer_to_cid = {cid_to_customer[k]:k for k in cid_to_customer}\n","    \n","aid_cid_df = transactions[['customer_id','article_id']]\n","print(len(aid_to_article), len(cid_to_customer))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-15T14:38:30.340436Z","iopub.status.busy":"2022-04-15T14:38:30.339744Z","iopub.status.idle":"2022-04-15T14:38:30.343769Z","shell.execute_reply":"2022-04-15T14:38:30.343018Z","shell.execute_reply.started":"2022-04-15T14:38:30.340400Z"},"trusted":true,"id":"I7PZ3oh0xZuX"},"outputs":[],"source":["# tmp = transactions.groupby(['customer_id', 'article_id']).count().reset_index()[['customer_id', 'article_id', 'price']]\n","# # tmp = tmp.pivot(index='customer_id', columns='article_id', values='price')\n","# tmp"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-15T14:38:30.345265Z","iopub.status.busy":"2022-04-15T14:38:30.344857Z","iopub.status.idle":"2022-04-15T14:38:31.226782Z","shell.execute_reply":"2022-04-15T14:38:31.226033Z","shell.execute_reply.started":"2022-04-15T14:38:30.345224Z"},"trusted":true,"id":"gaMxjmd1xZuX"},"outputs":[],"source":["transactions = transactions.sort_values(by=['t_dat']).reset_index(drop = True)\n","mindate = min(transactions['t_dat'])\n","transactions['timespan'] = transactions['t_dat'].apply(lambda x: (x-mindate).days)\n","\n","transactions, transactions_val = transactions[:int(0.8*len(transactions))], transactions[int(0.8*len(transactions)):].reset_index(drop=True)\n","print(len(transactions), len(transactions_val))\n","print(len(customers), len(articles), len(articles['article_id'].unique()))\n","transactions.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-15T14:38:31.228072Z","iopub.status.busy":"2022-04-15T14:38:31.227852Z","iopub.status.idle":"2022-04-15T14:38:31.234037Z","shell.execute_reply":"2022-04-15T14:38:31.233250Z","shell.execute_reply.started":"2022-04-15T14:38:31.228046Z"},"trusted":true,"id":"oTYehHqtxZuX"},"outputs":[],"source":["list(aid2emb.keys())[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-15T14:38:31.235495Z","iopub.status.busy":"2022-04-15T14:38:31.235289Z","iopub.status.idle":"2022-04-15T14:38:31.252254Z","shell.execute_reply":"2022-04-15T14:38:31.251374Z","shell.execute_reply.started":"2022-04-15T14:38:31.235471Z"},"trusted":true,"id":"X_CaN-3-xZuX"},"outputs":[],"source":["class BatchIterator:\n","    def __init__(self, x, y, batch_size):\n","        self.batch_size = batch_size\n","        self.i = 0\n","        self.x = x\n","        self.y = y\n","\n","    def __iter__(self):\n","        return self\n","\n","    def __next__(self):\n","        if self.i * self.batch_size == len(self.y):\n","            raise StopIteration()\n","        mini_x = self.x[self.i * self.batch_size: (self.i + 1) * self.batch_size]\n","        mini_y = self.y[self.i * self.batch_size: (self.i + 1) * self.batch_size]\n","        self.i += 1\n","        return mini_x, mini_y\n","class CandidateBatchIterator(BatchIterator):\n","    # personal, purchase, candidate_train_label, batch_size, max_len\n","    #    x1       x2              y                  \n","    def __init__(self, x1, x2, y, batch_size, max_len):\n","        self.input_ids,self.token_type_ids,self.attention_mask = [],[],[]\n","        for i,t in enumerate(x2):\n","            encoded = tokenizer.encode_plus(text=t,max_length=max_len,padding='max_length',truncation=True)\n","            self.input_ids.append(encoded['input_ids'])\n","            self.token_type_ids.append(encoded['token_type_ids'])\n","            self.attention_mask.append(encoded['attention_mask'])\n","        self.input_ids,self.token_type_ids,self.attention_mask = torch.tensor(self.input_ids),\\\n","                        torch.tensor(self.token_type_ids),torch.tensor(self.attention_mask)\n","        \n","        self.batch_size = batch_size\n","        self.i = 0\n","        self.x1 = x1\n","#         self.x2 = x2\n","        self.y = y\n","        self.max_len = max_len\n","\n","    def __next__(self):\n","        if self.i * self.batch_size >= len(self.y):\n","            raise StopIteration()\n","        mini_x1 = self.x1[self.i * self.batch_size: (self.i + 1) * self.batch_size]\n","#         mini_x2 = self.x2[self.i * self.batch_size: (self.i + 1) * self.batch_size]\n","        mini_y = self.y[self.i * self.batch_size: (self.i + 1) * self.batch_size]\n","    \n","        min_input_ids = self.input_ids[self.i * self.batch_size: (self.i + 1) * self.batch_size]\n","        min_token_type_ids = self.token_type_ids[self.i * self.batch_size: (self.i + 1) * self.batch_size]\n","        min_attention_mask = self.attention_mask[self.i * self.batch_size: (self.i + 1) * self.batch_size]\n","        self.i += 1\n","#         return mini_x1, mini_x2, mini_y\n","        return mini_x1, mini_y, min_input_ids, min_token_type_ids, min_attention_mask\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-15T14:38:31.254057Z","iopub.status.busy":"2022-04-15T14:38:31.253469Z","iopub.status.idle":"2022-04-15T14:38:31.268767Z","shell.execute_reply":"2022-04-15T14:38:31.268050Z","shell.execute_reply.started":"2022-04-15T14:38:31.253934Z"},"trusted":true,"id":"93oGjcPXxZuY"},"outputs":[],"source":["def train_candidate_generation(model, get_batch_iter, item, batch_size):\n","#     optimizer = torch.optim.Adam(model.parameters(), lr=0.00001, betas=(0.9, 0.98), eps=1e-9)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n","    criteon = nn.BCELoss()\n","    epochs = 5\n","    for epoch in range(epochs):\n","        print('epoch', epoch)\n","        total_loss = 0\n","        batch_iter = get_batch_iter()\n","#         for iter_, (mini_personal, mini_watches, mini_label) in enumerate(batch_iter):\n","# mini_x1, mini_y, min_input_ids, min_token_type_ids, min_attention_mask\n","        for iter_, (mini_personal, mini_label, min_input_ids, min_token_type_ids, min_attention_mask)\\\n","          in enumerate(batch_iter):\n","#             out = model(mini_watches, mini_personal, item)\n","            out = model(min_input_ids, min_token_type_ids, min_attention_mask, mini_personal, item)\n","    \n","#             print('mini_label', mini_label)\n","#             loss = nn.MSELoss(reduction='sum')(out, mini_label)  # todo: use sigmoid cross entropy loss\n","            loss = criteon(out, mini_label)\n","            total_loss += loss.item()\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            if iter_ != 0 and (iter_ + 1) % 100 == 0:\n","                print(f'epoch: {epoch + 1}, iter: {iter_ + 1}, loss: {total_loss/10}')\n","                total_loss = 0\n","        print('epoch ends')\n","#             break\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-15T14:38:31.270331Z","iopub.status.busy":"2022-04-15T14:38:31.270017Z","iopub.status.idle":"2022-04-15T14:38:31.831164Z","shell.execute_reply":"2022-04-15T14:38:31.830207Z","shell.execute_reply.started":"2022-04-15T14:38:31.270303Z"},"trusted":true,"id":"VsXaQtRaxZuY"},"outputs":[],"source":["bert_path = 'bert-base-cased'\n","from transformers import BertTokenizer, BertForSequenceClassification, BertConfig, BertModel\n","class CandidateGeneration(nn.Module):\n","    def __init__(self, embed_item_size, hidden_size):\n","        super(CandidateGeneration, self).__init__()\n","        # self.embedding = nn.Embedding(num_embeddings=len(token2ix),\n","                                    #   embedding_dim=300)\n","        self.personal_fc = nn.Linear(1, embed_item_size)\n","        self.fc1 = nn.Linear(embed_item_size, hidden_size)  # noqa: E226\n","        self.fc2 = nn.Linear(hidden_size, embed_item_size)\n","        self.fc3 = nn.Linear(embed_item_size, embed_item_size)\n","        self.dropout = nn.Dropout(0.5)\n","    \n","        self.config = BertConfig.from_pretrained(bert_path)\n","        self.bert = BertModel.from_pretrained(bert_path)\n","        for param in self.bert.parameters():\n","            param.requires_grad=True\n","        self.fc = nn.Linear(self.config.hidden_size,embed_item_size)\n","\n","    def forward(self, input_ids,token_type_ids,attention_mask, personal_src, item_src):\n","#         print(context_src.shape, personal_src.shape, item_src.shape)\n","#         print('context_src', context_src,'\\npersonal_src', personal_src)\n","        personal_h = self.personal_fc(personal_src)  # (batch_size, n_personal, embed_item_size)\n","    \n","        output = self.bert(input_ids,token_type_ids,attention_mask)\n","        context_src = self.fc(output[1])\n","        context_src = context_src.reshape((personal_h.shape[0], 1, -1))\n","        # print(context_src.shape, personal_h.shape)\n","        h = torch.cat((context_src, personal_h), 1)  # (batch_size, 1+n_personal, embed_item_size)\n","        \n","        h = F.relu(self.fc1(h))\n","        h = self.dropout(h)\n","        h = F.relu(self.fc2(h))\n","        h = self.dropout(h)\n","        personal_context = F.relu(self.fc3(h))  # (batch_size, 1+n_personal, embed_item_size)\n","        # personal_context is (batch_size, embed_item_size)'s shape average, take inner prod with item_src\n","#         print(personal_context)\n","        out = torch.matmul(personal_context.mean(axis=1), item_src.t())  # (batch_size, n_item) = (batch_size, embed_item_size) * (embed_item_size, n_item)  # noqa: E501\n","        sigmoid = nn.Sigmoid()\n","        out = sigmoid(out) # (batch_size, n_item)\n","        return out\n","# cmodel = CandidateGeneration(embed_item_size, candidate_hidden_size)\n","# model = train_candidate_generation(cmodel, cbatch_iter, item, batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-15T14:38:31.832490Z","iopub.status.busy":"2022-04-15T14:38:31.832279Z","iopub.status.idle":"2022-04-15T14:38:34.238490Z","shell.execute_reply":"2022-04-15T14:38:34.237676Z","shell.execute_reply.started":"2022-04-15T14:38:31.832464Z"},"trusted":true,"id":"rOePcu0IxZuY"},"outputs":[],"source":["# n_item = article_emb.shape[0]  # articles used in training\n","# n_user = len(transactions['customer_id'].unique())\n","n_item, n_user = len(aid_to_article), len(cid_to_customer)\n","batch_size = 4  # split n_user using batch_size\n","LEARNING_RATE = 0.0005\n","## Generate article emb from prod_name,  detail_desc, ...\n","\n","# emb of articles. shape is (n_item, embed_item_size).\n","item = torch.tensor(article_emb).float() ;item = F.normalize(item)\n"," # emb dim\n","embed_item_size = item.shape[1] ; candidate_hidden_size = 64; candidate_size = 12  # number of recommend articles\n","\n","def get_dataset(customers, transactions):\n","    personal = np.array(customers[['age','FN','Active','club_member_status']])#  (n_customers, n_features)\n","    \n","    # get purchase data: cid-> [[pid_embeding], [e1,e2], []...]\n","    avg_fill = np.array([np.array(i) for i in aid2emb.values()]).mean(0)\n","    transactions = customers[['customer_id']].merge(transactions, on = 'customer_id', how = 'left')\n","    \n","    purchase = transactions.groupby('customer_id')['article_id'].apply(list).reset_index()\n","    purchase_true = purchase; purchase = purchase['article_id']\n","    \n","#     purchase = np.array([np.mean([aid2emb[i[j]] if i[j] in aid2emb else avg_fill for j in range(len(i))],axis=0) for i in purchase])\n","    tmp = []\n","    for i in purchase:\n","        text = ''\n","        for j in range(len(i)):\n","            if i[j] in aid2text:\n","                text += aid2text[i[j]]\n","                \n","        tmp.append(text)\n","    lengths = [len(i) for i in tmp]\n","    max_len = 512 # int(np.percentile(lengths,90))\n","    purchase = tmp\n","    \n","    # get labels\n","    candidate_train_label = torch.zeros((n_user, n_item))\n","    for i in range(len(transactions)):\n","        if transactions['article_id'][i] not in article_to_aid: continue\n","        cid = customer_to_cid[transactions['customer_id'][i]];aid = article_to_aid[transactions['article_id'][i]]; candidate_train_label[cid,aid] = 1\n","    print(candidate_train_label.shape, torch.sum(candidate_train_label)) # (n_customers, n_item)\n","\n","    personal = torch.tensor(personal.reshape(personal.shape[0], personal.shape[1],-1)).float()\n","    personal = torch.nan_to_num(personal)\n","    personal = F.normalize(personal)\n","    \n","#     purchase = torch.tensor(purchase.reshape(purchase.shape[0], -1, purchase.shape[1])).float()\n","#     purchase = F.normalize(purchase)\n","#     candidate_train_label = torch.tensor(candidate_train_label).float()\n","    return personal, purchase, candidate_train_label, purchase_true, max_len\n","    \n","personal, purchase, candidate_train_label, purchase_true, max_len = get_dataset(customers, transactions)\n","personal_val, purchase_val, candidate_val_label, purchase_true_val, max_len_val = get_dataset(customers, transactions_val)\n","# (n_customers, n_features)\n","    \n","cbatch_iter = lambda: CandidateBatchIterator(personal, purchase, candidate_train_label, batch_size, max_len)  # noqa: E731\n","cbatch_iter_val = lambda: CandidateBatchIterator(personal_val, purchase_val, candidate_val_label, batch_size, max_len)  # noqa: E731\n","print('personal',personal.shape, 'purchase',len(purchase), 'candidate_train_label',candidate_train_label.shape, batch_size)\n","print('personal_val',personal_val.shape, 'purchase_val',len(purchase), 'candidate_val_label',candidate_val_label.shape, batch_size)\n","# print(personal.dtype, purchase.dtype, candidate_train_label.dtype, batch_size)\n","print('item',item.dtype, item.shape) # (n_item, embed_item_size).[xxx, 63]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-15T14:38:34.241814Z","iopub.status.busy":"2022-04-15T14:38:34.241441Z","iopub.status.idle":"2022-04-15T16:00:15.511372Z","shell.execute_reply":"2022-04-15T16:00:15.510544Z","shell.execute_reply.started":"2022-04-15T14:38:34.241780Z"},"trusted":true,"id":"T5JkVd2IxZuZ"},"outputs":[],"source":["# # model\n","import warnings\n","warnings.filterwarnings('ignore')\n","tokenizer = BertTokenizer.from_pretrained(bert_path)\n","cmodel = CandidateGeneration(embed_item_size, candidate_hidden_size)\n","model = train_candidate_generation(cmodel, cbatch_iter, item, batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-15T12:48:13.889399Z","iopub.status.busy":"2022-04-15T12:48:13.889108Z","iopub.status.idle":"2022-04-15T12:48:13.900120Z","shell.execute_reply":"2022-04-15T12:48:13.899548Z","shell.execute_reply.started":"2022-04-15T12:48:13.889366Z"},"trusted":true,"id":"61QL7qPUxZuZ"},"outputs":[],"source":["purchase_true_val.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-15T16:48:15.295678Z","iopub.status.busy":"2022-04-15T16:48:15.295362Z","iopub.status.idle":"2022-04-15T17:03:27.174119Z","shell.execute_reply":"2022-04-15T17:03:27.173179Z","shell.execute_reply.started":"2022-04-15T16:48:15.295646Z"},"trusted":true,"id":"NGxMrQraxZuZ"},"outputs":[],"source":["def evaluate_candidate_generation(model, get_batch_iter, item, batch_size, purchase_true_val):\n","    model.eval()\n","    batch_iter = get_batch_iter()\n","    prediction = []\n","#     for iter_, (mini_personal, mini_watches, mini_label) in enumerate(batch_iter):\n","    for iter_, (mini_personal, mini_label, min_input_ids, min_token_type_ids, min_attention_mask)\\\n","          in enumerate(batch_iter):\n","#             out = model(mini_watches, mini_personal, item)\n","        out = model(min_input_ids, min_token_type_ids, min_attention_mask, mini_personal, item)\n","    \n","#         out = model(mini_watches, mini_personal, item)\n","#         print(out, out.shape)\n","        indexes = np.argpartition(out.detach().numpy(),-12)\n","        indexes = [i[-12:] for i in indexes]\n","        for line in indexes:\n","            pred = []\n","            for idx in range(len(line)):\n","                pred.append(str(aid_to_article[line[idx]]))\n","            prediction.append(' '.join(pred))\n","        if iter_ != 0 and (iter_ + 1) % 1000 == 0:\n","            print(f'epoch: {epoch + 1}, iter: {iter_ + 1}, loss: {total_loss/10}')\n","            total_loss = 0\n","#         break\n","    print('len(prediction)',len(prediction))\n","    def get_sring_truth(x):\n","        if str(x[0]) == 'nan': return ''\n","        return ' '.join(list(map(str, list(map(int,x)))))\n","    res = purchase_true_val\n","    res['valid_true'] = res['article_id'].apply(lambda x: get_sring_truth(x));res['prediction'] = prediction;  # res['prediction'][:50] = res['article_id'][:50].apply(lambda x: get_sring_truth(x))\n","    return res\n","val_res = evaluate_candidate_generation(model, cbatch_iter_val, item, batch_size, purchase_true_val)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-15T17:03:27.176058Z","iopub.status.busy":"2022-04-15T17:03:27.175482Z","iopub.status.idle":"2022-04-15T17:03:27.189878Z","shell.execute_reply":"2022-04-15T17:03:27.189268Z","shell.execute_reply.started":"2022-04-15T17:03:27.176023Z"},"trusted":true,"id":"xEQQt1LuxZuZ"},"outputs":[],"source":["calculate_mapk(val_res)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:48:06.810455Z","iopub.status.idle":"2022-04-15T12:48:06.810798Z","shell.execute_reply":"2022-04-15T12:48:06.810647Z","shell.execute_reply.started":"2022-04-15T12:48:06.810618Z"},"trusted":true,"id":"rd1Wo_7qxZuZ"},"outputs":[],"source":["# torch.save(model.state_dict(), os.path.join('_dir,name'))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:48:06.811743Z","iopub.status.idle":"2022-04-15T12:48:06.812111Z","shell.execute_reply":"2022-04-15T12:48:06.811909Z","shell.execute_reply.started":"2022-04-15T12:48:06.811887Z"},"trusted":true,"id":"aq3Y0VhtxZuZ"},"outputs":[],"source":["sample_submission = pd.read_csv(os.path.join(data_dir,'sample_submission.csv'), nrows = 100)\n","# sample_submission.head()\n","print(type(sample_submission['customer_id'][0]), sample_submission['customer_id'][0])\n","print(type(sample_submission['prediction'][0]), sample_submission['prediction'][0])\n","print(sample_submission['prediction'][0].split())\n","sample_submission.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"id":"48xidParxZuZ"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:48:06.814256Z","iopub.status.idle":"2022-04-15T12:48:06.814633Z","shell.execute_reply":"2022-04-15T12:48:06.814481Z","shell.execute_reply.started":"2022-04-15T12:48:06.814456Z"},"trusted":true,"id":"uGBy0-xvxZua"},"outputs":[],"source":["\n","#     candidate_train_label = np.array(transactions.groupby(['customer_id', 'article_id']).count().reset_index()\\\n","#         .pivot(index='customer_id', columns='article_id', values='price').fillna(0))\n","\n","# n_item = article_emb.shape[0]  # articles used in training\n","# n_user = len(transactions['customer_id'].unique())\n","# batch_size = 4  # split n_user using batch_size\n","# ## Generate article emb from prod_name, product_type_name, product_group_name, \n","# # graphical_appearance_name, colour_group_name, perceived_colour_value_name, \n","# # perceived_colour_master_name, department_name, index_name, garment_group_name,\n","# # detail_desc\n","# embed_item_size = 64\n","# # item = torch.tensor(get_item_vector(n_item))  # emb of articles. shape is (n_item, embed_item_size).\n","# item = torch.rand((n_item, embed_item_size))\n","# # print('emb shape (n_item, embed_item_size):', article_emb.shape)\n","# candidate_hidden_size = 64  \n","# candidate_size = 12  # number of recommend articles\n","\n","# ages = torch.randint(0, 100, (n_user, 1, 1), dtype=torch.float)  # (n_user, 1, 1)\n","# gender = torch.randint(0, 2, (n_user, 1, 1), dtype=torch.float)  # (n_user, 1, 1)\n","# personal = torch.cat((ages, gender), 1)  # (n_user, n_personal)  # [[age, sex], [age, sex], ...]\n","# watches = torch.randn(n_user, 1, embed_item_size)  # 視聴した全ての動画の特徴量ベクトルを平均したものと仮定. つまり↓3行のを行ったのと等価.\n","\n","# avg_fill = np.array([np.array(i) for i in aid2emb.values()]).mean(0)\n","# purchase = np.array(transactions.groupby('customer_id')['article_id'].apply(list).reset_index()['article_id'])\n","# # print(len(purchase)) # 104 customers\n","# purchase = np.array([np.mean([aid2emb[i[j]] if i[j] in aid2emb else avg_fill for j in range(len(i))], axis=0) for i in purchase])\n","# # print(purchase.shape) # (104, 64)\n","\n","# candidate_train_label = torch.randint(0, 10, (n_user, n_item), dtype=torch.float)\n","\n","# cbatch_iter = lambda: CandidateBatchIterator(personal, watches, candidate_train_label, batch_size)  # noqa: E731\n","# print(personal.shape, watches.shape, candidate_train_label.shape, batch_size)\n","# # model\n","# cmodel = CandidateGeneration(embed_item_size, candidate_hidden_size)\n","# train_candidate_generation(cmodel, cbatch_iter, item, batch_size)\n","\n","# item.shape"]},{"cell_type":"markdown","metadata":{"id":"h7T6UgBtxZua"},"source":["### ranking"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:48:06.815686Z","iopub.status.idle":"2022-04-15T12:48:06.816281Z","shell.execute_reply":"2022-04-15T12:48:06.816104Z","shell.execute_reply.started":"2022-04-15T12:48:06.816081Z"},"trusted":true,"id":"3v8iuCcZxZua"},"outputs":[],"source":["# ranking_hidden_size = 248\n","# purchase_price_feature_size = 1\n","# candidate_size = 12\n","# ranking_train_label = torch.tensor(candidate_train_label.reshape(-1)).float()\n","\n","# print('ranking_train_label',ranking_train_label.shape)\n","\n","# purchase_price_vector = torch.tensor(\n","#     np.array(transactions.groupby(['customer_id', 'article_id']).mean().reset_index()\\\n","#         .pivot(index='customer_id', columns='article_id', values='price').fillna(0)).reshape(-1,1)).float()\n","# print('purchase_price_vector',purchase_price_vector.shape)\n","\n","# rbatch_iter = lambda: BatchIterator(purchase_price_vector, ranking_train_label, batch_size)  # noqa: E731\n","# # model\n","# rmodel = Ranking(purchase_price_feature_size, ranking_hidden_size, candidate_size)\n","# # train_ranking(rmodel, rbatch_iter, batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z_L2NGpoxZub"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"FsmqZ-rPxZub"},"source":["### Prev"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-04-15T12:48:06.817894Z","iopub.status.idle":"2022-04-15T12:48:06.818267Z","shell.execute_reply":"2022-04-15T12:48:06.818114Z","shell.execute_reply.started":"2022-04-15T12:48:06.818088Z"},"trusted":true,"id":"OoqoPLahxZub"},"outputs":[],"source":["# watch_time_feature_size = 124\n","# ranking_hidden_size = 248\n","# candidate_size = 10\n","# # data\n","# # Assumed to be the average of the feature vectors of the articles viewed among the candidate articles.\n","# watch_video_vector = torch.randint(0, 10, (n_user * n_item, 1, embed_item_size))  \n","# # print('n_user', n_user, 'n_item',n_item, watch_video_vector.shape)\n","# # # Feature vector of target article to predict browsing time\n","# target_video_vector = torch.randint(0, 10, (n_user * n_item, 1, embed_item_size))  \n","# video_vector = torch.cat((watch_video_vector, target_video_vector), 1)  # (n_user*n_item, 2, embed_item_size)\n","# real_impression_matrix = torch.randint(3, 9, (n_user, n_item), dtype=torch.float)  # (n_user, n_item)\n","# real_watch_time_matrix = torch.empty(n_user, n_item).uniform_(0, 10)  # (n_user, n_item)\n","# # print('aaa',F.softmax(real_watch_time_matrix / real_impression_matrix, dim=-1).shape)\n","# ranking_train_label = F.softmax(real_watch_time_matrix / real_impression_matrix, dim=-1).reshape(-1)  # (n_user*n_item)\n","# print('ranking_train_label',ranking_train_label.shape)\n","\n","# watch_time_vector = torch.rand((n_user*n_item, watch_time_feature_size))\n","# print('watch_time_vector',watch_time_vector.shape)\n","\n","# rbatch_iter = lambda: BatchIterator(watch_time_vector, ranking_train_label, batch_size)  # noqa: E731\n","# # model\n","# rmodel = Ranking(watch_time_feature_size, ranking_hidden_size, candidate_size)\n","# # train_ranking(rmodel, rbatch_iter, batch_size)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"colab":{"name":"hm-recommend-transfer-learning.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":0}